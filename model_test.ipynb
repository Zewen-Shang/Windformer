{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils.command.config import config\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.backends import cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import time\n",
    "from dataset import *\n",
    "from utils import MAPE\n",
    "from config import args,models\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_model(model,dataloader,device):\n",
    "    total_MSE,total_MAPE = 0.,0.\n",
    "    total_num = 0\n",
    "    for imgs,targets in dataloader:\n",
    "        imgs = imgs.to(device)\n",
    "        targets = targets.to(device).squeeze()\n",
    "        output = model(imgs).squeeze()\n",
    "        mse = nn.MSELoss()(output,targets)\n",
    "        mape = MAPE(targets,output)\n",
    "        total_MSE += mse * len(imgs)\n",
    "        total_MAPE += mape * len(imgs)\n",
    "        total_num += len(imgs)\n",
    "    return total_MSE / total_num,total_MAPE / total_num\n",
    "\n",
    "window_size,predict_steps = args[\"window_size\"],args[\"predict_steps\"]\n",
    "\n",
    "def test_time_displace(dataset_test):\n",
    "    targets = []\n",
    "    for data_item in dataset_test:\n",
    "        targets.append(data_item[1])\n",
    "    targets = torch.tensor(targets)\n",
    "    output = targets.clone()\n",
    "    output[predict_steps:] = targets[:len(targets)-predict_steps]\n",
    "    for i in range(predict_steps):\n",
    "        output[i] = output[0]\n",
    "    return nn.MSELoss()(output,targets).item()\n",
    "\n",
    "\n",
    "# generate_img()\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "torch.manual_seed(300)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare Data : 94.072256 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# 23,15\n",
    "dataset = get_dataset_img([15,10],window_size,predict_steps,debug=True)\n",
    "# for i in range(len(dataset)):\n",
    "#     dataset[i][0] = dataset[i][0][5:]\n",
    "\n",
    "cut_pos = int(0.5 * len(dataset))\n",
    "dataset_train = dataset[:cut_pos]\n",
    "dataset_test = dataset[cut_pos:]\n",
    "\n",
    "# print(test_time_displace(dataset_test))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Prepare Data : %f s\"%(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"Mult_Conv\"\n",
    "epoch = 200\n",
    "batch_size = 128\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train,batch_size=batch_size,shuffle=True,num_workers=4,pin_memory=True)\n",
    "dataloader_test = DataLoader(dataset_test,batch_size=batch_size,num_workers=4,pin_memory=True)\n",
    "\n",
    "model = models[model_name](**args[model_name])\n",
    "model.to(device)\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=1e-3)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for i in range(epoch):\n",
    "    if(i == 10):\n",
    "        lr *= 0.1\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    # if(i == 70):\n",
    "    #     lr *= 0.1\n",
    "    #     for param_group in optimizer.param_groups:\n",
    "    #         param_group['lr'] = lr\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    for imgs,targets in dataloader_train:\n",
    "        imgs = imgs.to(device)\n",
    "        targets = targets.to(device).squeeze()\n",
    "        output = model(imgs).squeeze()\n",
    "        loss = criterion(output,targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    train_MSE,train_MAPE = test_model(model,dataloader_train,device)\n",
    "    test_MSE,test_MAPE = test_model(model,dataloader_test,device)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(\"Epoch %d : Train MSE : %f, Train MAPE : %f , Test MSE : %f , Test MAPE : %f , Lr : %f , Time: %f s .\" % (i,train_MSE,train_MAPE,test_MSE, test_MAPE ,optimizer.param_groups[0]['lr'],end-start))\n",
    "    writer.add_scalar('train_MSE', train_MSE.item(), i)\n",
    "    writer.add_scalar('train_MAPE', train_MAPE.item(), i)\n",
    "    writer.add_scalar('test_MSE', test_MSE.item(), i)\n",
    "    writer.add_scalar('test_MAPE', test_MAPE.item(), i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('conformer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "262ed32eccd92406117d49fb5b16c5a8144be2c09f2e745c98647df7bbbd989c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
